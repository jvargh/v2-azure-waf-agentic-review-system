**Detailed User Flow & Design Specification**

**Overview**

This document provides a comprehensive, step-by-step breakdown of the user journey through the Azure Well-Architected Review System, told as a narrative from the user\'s perspective at each stage.

**STEP 0: First Visit - Landing on Empty Dashboard**

**What the User Sees**

You arrive at the Azure Well-Architected Review System for the first time. The page greets you with a clean, professional interface showing the main heading \"Azure Well-Architected Review\" with the tagline \"Analyze your Azure architecture against the 5 pillars of excellence.\"

Four statistics cards are displayed across the top of the page, all showing zeros:

- 0 Total Reviews

- 0 Completed

- 0 In Progress

- N/A Avg Score

Below these metrics, you notice a prominent blue button labeled \"+ New Well-Architected Review\" that stands out as the primary call-to-action.

The \"Recent Reviews\" section shows an empty state with a document icon and the message \"No reviews yet. Create your first Azure Well-Architected Review.\"

**What the User Does**

You realize this is a fresh start - no previous assessments exist. The empty dashboard makes it clear that your first action should be creating a new review.

**Action:**Â You click the blue \"+ New Well-Architected Review\" button to begin your first architecture assessment.

**What Happens Next**

The page transitions to a form where you\'ll create your first assessment (STEP 1).

**\**

**STEP 1: Naming Your Architecture Review**

**What the User Sees**

After clicking the create button, you\'re taken to a clean form page with a \"â† Back to Dashboard\" link at the top if you need to cancel.

The page displays \"Create New Assessment\" as the main heading, with helpful context below: \"Start a new Azure Well-Architected Framework review for your architecture.\"

You see two input fields:

1.  **Assessment Name**Â (marked with a red asterisk indicating it\'s required)

2.  **Description**Â (marked as optional)

Below the form fields, there\'s a helpful light blue information box titled \"What\'s Next?\" that explains: \"After creating the assessment, you\'ll be able to upload architecture documents, diagrams, and other relevant files. Our AI agents will analyze your architecture against all 5 pillars of the Well-Architected Framework.\"

At the bottom of the form, two buttons are visible: a gray \"Cancel\" button on the left and a blue \"Create Assessment\" button on the right.

**What the User Does**

**Step 1:**Â You click into the \"Assessment Name\" field and begin typing. You decide to name it after your project: \"Frontier Inc. -- LLM Mode\". As you type, the system may show autocomplete suggestions based on naming patterns.

**Step 2:**Â You consider adding a description and click into the optional description field. You type \"Frontier Inc.\" to provide some basic context about the architecture, though you could leave this blank if you wanted.

**Step 3:**Â With the required name field filled in, you notice the \"Create Assessment\" button is ready to click. You review your entries:

- Name: \"Frontier Inc.\"

- Description: \"Frontier Inc.\"

Satisfied with these details, you click the blue \"Create Assessment\" button.

**What Happens Next**

The form submits your data to the backend. Data persists in MongoDB even after website is shut down. The system creates a new assessment record and immediately returns you to the dashboard where your newly created assessment now appears in the list (STEP 2).

**Technical Details**

- **Local Install (MongoDB Community Edition)** with connectivity to mongodb://localhost:27017

- API Call:Â [POST /api/assessments]{.mark}Â with name and description

- Response: New assessment object with status \"pending\" and progress 0%

- Validation: Name is required; description is optional

- On success: Navigates back to dashboard with refreshed assessment list**\**

**STEP 2: Seeing Your New Assessment**

**What the User Sees**

You\'re back on the dashboard, but now it looks different. The statistics have updated:

- **1**Â Total Review (changed from 0)

- **0**Â Completed (still zero - you haven\'t analyzed anything yet)

- **0**Â In Progress (still zero - not analyzing yet)

- **NaN%**Â Avg Score (shows NaN since no completed assessments exist **but use 0 instead)**

In the \"Recent Reviews\" section, you now see your newly created assessment displayed as a card:

**\"Frontier Inc. - LLM mode\"**Â with a yellow \"Pending\" badge on the right

- Below the title: \"ğŸ“„ 0 documents ğŸ“… with date/time on when assessment was created\"

- On the far right: A small trash icon ğŸ—‘ï¸ and a forward arrow â†’ to go to next step

**What the User Does**

You see your assessment is ready to work with but notice it has 0 documents uploaded and shows a \"Pending\" status. You understand that the next step is to open this assessment and add your architecture documentation.

**Action:**Â You click anywhere on the assessment card (or specifically on the arrow icon on the right side) to open the assessment details.

*Alternative action you could take:*Â You could also click the trash icon if you wanted to delete this assessment, which would show a confirmation dialog before removing it.

**What Happens Next**

The assessment detail page opens, automatically showing you the Upload Documents tab where you can begin adding files to your review (STEP 3).

**Technical Details**

- Updated state:Â [{ assessments: \[newAssessment\], \... }]{.mark}

- Assessment object contains: id, name, description, status: \"pending\", progress: 0, documents: \[\]

- Clicking card triggers:Â [setSelectedAssessment(assessment)Â andÂ setCurrentView(\'assessment\')]{.mark}

**\**

**STEP 3: Preparing to Upload Your Architecture Files**

**What the User Sees**

The assessment detail page opens with your assessment name \"Frontier Inc. - LLM mode\" at the top, along with the yellow \"Pending\" status badge. A \"â† Back to Dashboard\" link is available in the top-left corner.

You see four tabs across the page:

1.  **ğŸ“„ Upload Documents**Â (currently selected, underlined in blue)

2.  ğŸ” Uploaded Artifact Findings

3.  âš¡ Analysis Progress

4.  ğŸ“Š Results & Scorecard

The main content area shows:

- **Title:**Â \"Upload Architecture Documents, Images & CSV Files\"

- **Description:**Â \"Upload your architecture diagrams, documentation, and CSV support case files. Our AI agents will analyze these against the 5 pillars.\"

In the center of the page is a large dashed-border upload area with:

- A document/upload icon ğŸ“

- Text: \"Drop files here or click to upload\"

- Accepted file types listed below:

  - ğŸ“„ Documents: PDF, DOC, TXT

  - ğŸ–¼ï¸ Images: PNG, JPG, SVG

  - ğŸ“Š CSV: Support Case Data

**What the User Does**

You understand that you need to upload your architecture files before any analysis can begin. You have your architecture documentation ready in a folder on your computer.

**Action:**Â You click anywhere in the dashed upload area. This should automatically enable multi-file selection as seen in Step 4.

**What Happens Next**

Your operating system\'s file picker dialog opens, allowing you to navigate to your files and select which ones to upload (STEP 4).

*Alternative action:*Â You could also drag and drop files directly onto the upload area instead of clicking.

**Technical Details**

- Component:Â [AssessmentDetailÂ â†’Â UploadTab]{.mark}

- Current tab state:Â [currentTab: \'upload\']{.mark}

- Assessment has:Â [documents: \[\]]{.mark}Â (empty)

- File input accepts:Â [.pdf,.doc,.docx,.txt,.md,.png,.jpg,.jpeg,.svg,.csv]{.mark}

- Multiple file selection enabled

**\**

**STEP 4: Selecting Your Architecture Files**

**What the User Sees**

Your operating system\'s file picker window opens. You see your file system navigation on the left side and the current folder contents in the main area.

You\'ve navigated to: Desktop \> WellArchAgents \> well-architected-agentic-review \>Â **sample_data**

In this folder, you see several files:

- ğŸ“Â **sample_architecture_images/**Â (a folder)

- ğŸ“„Â **architecture_document.txt**Â (TXT File - 8 KB)

- ğŸ“ŠÂ **azure_support_cases.csv**Â (Microsoft Excel CSV - 8 KB)

- ğŸ“„ README.md (Markdown Source - 8 KB)

- ğŸ“„ simple_architecture.txt (TXT File - 1 KB)

At the bottom of the dialog, there\'s a file name field and two buttons: \"Cancel\" and \"Open\" (the Open button is blue/highlighted).

**What the User Does**

**Step 1:**Â You scan through the available files and identify which ones contain your architecture information. You decide you need:

- The main architecture document

- The support cases data for historical analysis

**Step 2:**Â You select multiple files by:

- Clicking onÂ **architecture_document.txt**Â (it highlights)

- Holding Ctrl (Windows) or Cmd (Mac) and clicking onÂ **azure_support_cases.csv**Â (both are now highlighted)

You can see both filenames appear in the \"File name\" field at the bottom: \"azure_support_cases.csv\" \"architecture_document.txt\"

**Step 3:**Â With your two files selected, you click the blue \"Open\" button in the bottom-right corner.

**What Happens Next**

The file picker closes and you return to the upload tab. Your selected files immediately begin uploading to the system. You\'ll see the upload progress and then the uploaded files appear in a list (STEP 5).

**Technical Details**

- File picker: Native OS dialog

- Multiple selection: Enabled viaÂ [multiple]{.mark}Â attribute on file input

- Selected files: 2 files totaling \~16 KB

- Files:Â [architecture_document.txt,Â azure_support_cases.csv]{.mark}**\**

**STEP 5: Watching Your Files Upload**

**What the User Sees**

You\'re back on the Upload Documents tab, but now the page has updated to show your upload in progress and then your successfully uploaded files.

The same dashed-border upload area is still at the top (you can upload more files if needed).

Below it a new section has appeared:

**\"Uploaded Documents (2)\"**

You see both of your files listed. After the file content gets extracted from the files, the content now gets an LLM analysis to provide proper structure so that it provides clear and precise information needed by the 5 well-architected agents to perform their analysis.

1.  **ğŸ“„ architecture_document.txt**Â with a light purple badge \"ğŸ“˜ Architecture Doc\" and the content type \"text/plain\"

2.  **ğŸ“Š azure_support_cases.csv**Â with a green badge \"ğŸ“Š Case Analysis Data\" and the content type \"text/csv\"

At the bottom right of the page, a prominent blue button has appeared that wasn\'t there before:

**\"ğŸš€ Start Enhanced Well-Architected Analysis\"**

**What the User Does**

You notice that your files have been successfully uploaded. The system has automatically categorized them:

- Your architecture document as an \"Architecture Doc\"

- Your CSV file as \"Case Analysis Data\"

You\'re pleased to see both files uploaded successfully. The user switches to the \"Uploaded Artifact Findings\" tab. After the file content gets extracted from the files, the LLM-cleaned content is displayed here.

**What Happens Next**

On the Uploaded Artifact Findings tab you can review what the system understands about each of your uploaded files (STEP 6).

If content on this tab looks good, you should navigate back to the Upload tab using the tab navigation and click the blue \"Start Enhanced Well-Architected Analysis\" button when you\'re ready.

**Technical Details**

- Files uploaded via:Â [POST /api/assessments/{id}/documentsÂ (]{.mark}called once per file)

- Auto-navigation logic: Triggers only on first upload whenÂ [documents.length === 0]{.mark}Â before upload

- Documents state updated with 2 document objects containing id, filename, content_type

- Start Analysis button appears when:Â [documents.length \> 0 && status === \'pending\']{.mark}

**STEP 6: Reviewing What the AI Will Analyze**

**What the User Sees**

You\'re now on the \"ğŸ” Uploaded Artifact Findings\" tab (it\'s underlined, showing it\'s active). This tab shows you a detailed breakdown of what each uploaded file will contribute to your architecture analysis.

At the top, you see a summary with four yellow cards displaying statistics:

- **2**Â Total Documents

- **1**Â Architecture Docs

- **0**Â Architecture Diagrams

- **1**Â Case Analysis CSVs

Below this, a yellow information box with a lightbulb icon explains: \"**AI Analysis Context:**Â These uploaded artifacts provide comprehensive context for the AI-powered Well-Architected review. Architecture documents inform textual analysis, diagrams enable visual component recognition, and CSV files provide historical case patterns for reactive analysis recommendations.\"

**Architecture Documents Section**

You see a section titled \"ğŸ“„ Architecture Documents (1)\" with an expanded card for your first file:

**architecture_document.txt**

- Shows: text/plain â€¢ 7.2 KB

- Upload date: 8/26/2025

A blue-bordered box explains: \"ï¿½ Architecture Document Context: This architecture document provides detailed context about your system design, components, and configurations. The AI agents will analyze this content to understand your architecture\...\"

Below that, a purple box shows the actual AI analysis results (which comes from the LLM analysis in the prior step): \"**ğŸ¤– Real AI Architecture Analysis:**

- Architecture Patterns: \'Microservices architecture\', \'API-first design\', \'Serverless computing\', \'Event-driven architecture\'\...\"

- A preview of the document content shows: \"Enhanced E-commerce Platform Architecture Document\...\"

**Case Analysis Data Section**

Scrolling down, you see \"ğŸ“Š Case Analysis Data (1)\" with a card for:

**azure_support_cases.csv**

- Shows: text/csv â€¢ 7.7 KB

- Upload date: 8/18/2025

A green-bordered box explains: \"ğŸ“Š CSV Case Analysis Context: This CSV file contains support case data that will be analyzed for patterns, trends, and Well-Architected Framework violations\...\"

Another box shows the AI\'s preliminary analysis (which comes from the LLM analysis in the prior step): \"**ğŸ¤– Real AI Case Analysis:**

- Part 1 patterns: \'Configuration errors leading to service disruptions (e.g., RBAC rule in AKS, DNS config in Virtual Network)\'\...\"

**What the User Does**

You take a moment to review the information. You\'re impressed that the system has already performed some initial AI analysis on your uploaded files and categorized them appropriately. You can see:

1.  Your architecture document has been scanned and the AI identified key patterns like microservices and serverless computing

2.  Your support cases CSV has been analyzed for common configuration error patterns

You understand that this preliminary analysis will feed into the comprehensive review when you start it.

**Action:**Â You\'ve reviewed the artifacts and are satisfied. You click on the \"ğŸ“„ Upload Documents\" tab to go back and start the analysis.

**What Happens Next**

You return to the Upload Documents tab where you\'ll click the \"Start Enhanced Well-Architected Analysis\" button to begin the full AI review (STEP 7).

**Technical Details**

- Component:Â [ArtifactFindingsTab]{.mark}

- Documents categorized by content type: CSV vs text/plain vs images

- In Real LLM mode: AI insights displayed from document.ai_insights

- File type detection: CSV (text/csv), Text (text/plain), Images (image/\*)

- Summary counts computed from documents array

**\**

**STEP 7: Starting the Analysis and Watching Progress**

**What the User Sees - Starting Analysis**

On the Upload Documents tab you see your two uploaded files listed, and most importantly, that blue button at the bottom right called **\"ğŸš€ Start Enhanced Well-Architected Analysis\".** On hitting that button it starts the analysis/review leading to the 'Analysis Progress' tab

**What the User Does - Initiating the Review**

You\'ve uploaded your files, reviewed what the AI found in them, and now you\'re ready for the comprehensive analysis.

**Action:**Â You click the blue \"Start Enhanced Well-Architected Analysis\" button.

The moment you click it, several things happen:

1.  The status badge at the top right changes from yellow \"Pending\" to blue \"Analyzing\"

2.  The page automatically switches to the \"âš¡ Analysis Progress\" tab

3.  You see the analysis begin in real-time!

**What the User Sees - Progress Screen**

The Analysis Progress tab is now active. You see:

**Header Section:**

- Title: \"Analysis Progress\"

- Description: \"Our specialized AI agents are analyzing your architecture against each pillar of the Well-Architected Framework.\"

**Overall Progress Bar:**Â A large progress indicator showing:

Overall Progress 65%

\[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘\]

**Pillar Analysis Status:**Â Below the overall progress, you see five cards representing the five pillars of the Well-Architected Framework. Each pillar has an icon, name, and description.

[Each pillar is represented by the 5 agents developed earlier and in this project. The agents are Reliability_Agent, Security_Agent, Cost_Agent, Operational_Agent and Performance_Agent.]{.mark}

1.  **ğŸ›¡ï¸ Reliability**Â (Green background, checkmark)

- \"Resiliency, availability, recovery\"

- Status: On completion it saysÂ **âœ“ Complete** (and in Green state) else it will be in **ğŸ”„ Analyzing**Â state (with animated spinner) and light-blue background. If analysis hasn't started then it will be in **â³ Waiting** and off-white background.

2.  **ğŸ”’ Security**Â (Green background, checkmark)

- \"Data protection, threat detection\"

- Status: On completion it saysÂ **âœ“ Complete** (and in Green state) else it will be in **ğŸ”„ Analyzing**Â state (with animated spinner) and light-blue background. If analysis hasn't started then it will be in **â³ Waiting** and off-white background.

3.  **ğŸ’° Cost Optimization**Â (Green background, checkmark)

- \"Cost modeling, budgets, reduce waste\"

- Status: On completion it saysÂ **âœ“ Complete** (and in Green state) else it will be in **ğŸ”„ Analyzing**Â state (with animated spinner) and light-blue background. If analysis hasn't started then it will be in **â³ Waiting** and off-white background.

4.  **âš™ï¸ Operational Excellence**Â (Blue background, spinning icon)

- \"Monitoring, DevOps practices\"

- Status: Currently shows as in **ğŸ”„ Analyzing**Â state (with animated spinner) and light-blue background. If analysis hasn't started then it will be in **â³ Waiting** and off-white background.

5.  **âš¡ Performance Efficiency**Â (Gray/white background)

- \"Scalability, load testing\"

- Status: Currently showsÂ **â³ Waiting** state but when out of this state, goes to Analyzing and on completion to Complete.

**What the User Does - Watching the Analysis**

You watch as the progress unfolds. The system is currently at 65%, which means:

- The first three pillars (Reliability, Security, Cost Optimization) have been completed

- The fourth pillar (Operational Excellence) is actively being analyzed right now

- The fifth pillar (Performance Efficiency) is waiting to begin

You notice the progress bar smoothly animates as it advances. Every few seconds, the page refreshes automatically and you might see:

- The progress percentage increase (65% â†’ 70% â†’ 75%\...)

- The currently analyzing pillar change status

- The next pillar\'s status change from \"Waiting\" to \"Analyzing\"

You don\'t need to refresh the page or click anything - the system automatically polls for updates every 2 seconds.

**What you\'re experiencing:**Â You\'re watching a live, real-time analysis as five specialized AI agents work through each pillar of the Well-Architected Framework, examining your architecture documents and support case history.

**What Happens Next**

You continue watching as the analysis progresses:

- 65% â†’ 70% â†’ 75% (Operational Excellence completes)

- 80% â†’ 90% (Performance Efficiency begins and progresses)

- 100% (All pillars complete!)

When the progress reaches 100%, two things happen automatically:

1.  A success message appears: \"âœ… Analysis Complete! Check the Results tab for your scorecard.\"

2.  The page automatically switches to the \"ğŸ“Š Results & Scorecard\" tab

You\'re taken to STEP 8 where you can review your comprehensive architecture assessment.

**Technical Details**

**API Call to Start Analysis:**

POST /api/assessments/{id}/analyze

Response:

{

\"status\": \"analyzing\",

\"message\": \"Analysis started\"

}

**Backend Process:**

async def analyze_assessment(assessment_id):

*\# Progress updates sent in real-time*

await update_progress(assessment_id, 0, \"Starting analysis\")

*\# Reliability pillar (0-20%)*

await update_progress(assessment_id, 10, \"Analyzing reliability\...\")

await update_progress(assessment_id, 20, \"Reliability complete\")

*\# Security pillar (20-40%)*

await update_progress(assessment_id, 30, \"Analyzing security\...\")

await update_progress(assessment_id, 40, \"Security complete\")

*\# Cost Optimization (40-60%)*

await update_progress(assessment_id, 50, \"Analyzing cost\...\")

await update_progress(assessment_id, 60, \"Cost optimization complete\")

*\# Operational Excellence (60-80%)*

await update_progress(assessment_id, 70, \"Analyzing operations\...\")

await update_progress(assessment_id, 80, \"Operational excellence complete\")

*\# Performance Efficiency (80-100%)*

await update_progress(assessment_id, 90, \"Analyzing performance\...\")

await update_progress(assessment_id, 100, \"All pillars complete\")

**Frontend Polling:**

useEffect(() =\> {

let interval;

if (assessmentData?.status === \'analyzing\') {

interval = setInterval(() =\> {

fetchAssessmentDetails(); *// Poll every 2 seconds*

}, 2000);

}

*// Auto-navigate to results when complete*

if (assessmentData?.status === \'completed\' && !scorecard) {

fetchScorecard();

setCurrentTab(\'results\');

}

return () =\> clearInterval(interval);

}, \[assessmentData?.status\]);

**Progress Calculation Logic:**

*// Each pillar = 20% of total*

const isCompleted = assessment?.progress \>= (index + 1) \* 20 \|\|

assessment?.progress === 100 \|\|

assessment?.status === \'completed\';

const isAnalyzing = assessment?.progress \> index \* 20 &&

assessment?.progress \< (index + 1) \* 20 &&

assessment?.progress \< 100 &&

assessment?.status !== \'completed\';

**\**

**Visual State Indicators:**

  -----------------------------------------------------------------------
  State       Background                     Icon            Text Color
  ----------- ------------------------------ --------------- ------------
  Waiting     Gray ([bg-white]{.mark})       â³              Gray

  Analyzing   Blue ([bg-blue-50)]{.mark}     ğŸ”„ (spinning)   Blue

  Complete    Green ([bg-green-50)]{.mark}   âœ“               Green
  -----------------------------------------------------------------------

**\**

**STEP 8: Reviewing Your Architecture Scorecard**

**What the User Sees - Automatic Navigation**

The moment the analysis reaches 100%, the page automatically switches to the \"ğŸ“Š Results & Scorecard\" tab. The status badge at the top changes from blue \"Analyzing\" to green \"Completed.\"

You\'re now looking at your comprehensive Well-Architected Framework assessment results!

**Overall Score - First Impression**

At the top of the page, you see a prominent yellow banner with \"Well-Architected Scorecard\" and below it, a large circular score display: **74.6%**

This is displayed in large, bold text (color-coded yellow since it\'s between 60-79%, which is \"Good\"). Below the score, you see \"Overall Architecture Score.\"

You immediately understand that your architecture scored 74.6% overall across all five pillars - a solid score, though there\'s room for improvement to reach the excellent tier (80%+).

**Pillar Breakdown - Detailed Scores**

Scrolling down, you see a section titled \"Pillar Breakdown\" with five cards arranged in a grid (3 columns, wrapping to 2 rows).

**Card 1: Reliability - 80% (Green)**

You see your Reliability pillar scored 80% - excellent! The card shows:

- Overall pillar score:Â **80%**Â in green

- Subcategory breakdown: Even though it shows the below subcategories, they should be redone based on what has been configured with the **Reliability** agent.

  - High Availability

  - Disaster Recovery

  - Fault Tolerance

  - Backup Strategy

  - Monitoring

**Card 2: Security - 82% (Green)**

Your Security pillar also scored in the excellent range at 82%:

- Subcategory breakdown: Even though it shows the below subcategories, they should be redone based on what has been configured with the **Security** agent.

  - Identity & Access Management

  - Data Protection

  - Network Security

  - Security Monitoring

  - Compliance

**Card 3: Cost Optimization - 58.8% (Yellow)**

This pillar is in the \"needs improvement\" range at 58.8%.

- Subcategory breakdown: Even though it shows the below subcategories, they should be redone based on what has been configured with the **Cost Optimization** agent.

  - Resource Right-sizing

  - Reserved Capacity

  - Cost Monitoring and Governance Cost

  - Automation & Scaling

  - Waste Elimination

You note this as an area requiring attention.

**Card 4: Operational Excellence - 75% (Yellow)**

Good score at 75%, just below the excellent threshold:

- Subcategory breakdown: Even though it shows the below subcategories, they should be redone based on what has been configured with the **Cost Optimization** agent.

  - DevOps & Deployment

  - Monitoring & Observability

  - Automation & Infrastructure as Code

  - Incident Response & Management

  - Continuous Improvement

**Card 5: Performance Efficiency - 82% (Green)**

Strong performance at 82%:

- Subcategory breakdown: Even though it shows the below subcategories, they should be redone based on what has been configured with the **Performance Efficiency** agent.

  - Scalability & Elasticity

  - Resource Optimization

  - Caching & Content Delivery

  - Database Performance

  - Network Optimization

**Recommendations - Action Items**

Below the pillar cards, you see a yellow \"Recommendations\" header. This section contains detailed, AI-generated recommendations for improving your architecture.

**Recommendation 1 (Medium Priority - Yellow Badge)**

**Title:**Â \"Reasoning: The architecture makes good use of microservices, reducing the risk of a single point of failure\"

**Pillar:**Â Reliability â€¢ Real LLM Generated

You expand this card and read:

**ğŸ¤– AI Insight:**Â \"The architecture makes good use of microservices, reducing the risk of a single point of failure. Services like Azure Kubernetes Service and Azure Container Instances provide container orchestration and autoscaling which enhances fault tolerance. However, specific details on handling individual microservice failures or degradations aren\'t fully outlined, which suggests room for improvement in this area.\"

**Details Section (in blue box):**Â You see the full LLM analysis breaking down:

- High Availability: 85 with detailed reasoning about Azure services

- Specific mentions of AKS, Azure Container Instances, Azure SQL Database with read replicas

**Impact:**Â \"Improves application performance by 40-70% and handles traffic spikes\"Â **Effort:**Â MediumÂ **Azure Service:**Â Azure Kubernetes Service â†’ (clickable link)

**Recommendation 2 (Medium Priority)**

**Title:**Â \"Data Protection: 90 Detailed Reasoning: The implementation of Azure SQL Da\...\"

**Pillar:**Â Security â€¢ Real LLM Generated

You read through this recommendation about improving data protection using Azure SQL Databases with read replicas and Azure Cosmos DB with global distribution.

**Impact:**Â \"Improves security posture based on AI analysis\"Â **Effort:**Â MediumÂ **Azure Service:**Â Azure SQL Database â†’ (clickable link)

**What the User Does - Reviewing and Planning**

You take your time scrolling through all the results:

1.  **You note your strengths:**

- Security (82%), Performance Efficiency (82%), and Reliability (80%) are all in the excellent range

- Your use of microservices and managed services is well-recognized

2.  **You identify improvement areas:**

- Cost Optimization (58.8%) needs significant work

- Operational Excellence (75%) could be improved to reach the excellent tier

3.  **You review each recommendation:**

- Reading the AI\'s detailed reasoning

- Understanding the impact and effort required

- Clicking on Azure service links to learn more about suggested solutions

4.  **You make mental notes**Â (or actual notes) about:

- Which recommendations to prioritize (High priority first)

- Which improvements would have the most impact

- What resources you\'d need to implement changes

**What Happens Next**

You\'ve completed your first Well-Architected review! You now have:

- A comprehensive scorecard showing how your architecture performs across all five pillars

- Detailed subcategory scores identifying specific strengths and weaknesses

- AI-generated recommendations with specific Azure services to consider

- A baseline to measure future improvements against

**Possible Actions:**

- Click \"Back to Dashboard\" to see this assessment in your list

- Export or screenshot these results for your team

- Start implementing the high-priority recommendations

- Create a new assessment after making improvements to track progress

You feel confident that you now have a clear, data-driven understanding of your architecture\'s maturity and a roadmap for improvement.

**Technical Details**

- Auto-navigation triggered when:Â progress === 100 && status === \'completed\'

- API Call:Â GET /api/assessments/{id}/scorecard

- Score color coding: Green (â‰¥80%), Yellow (â‰¥60%), Red (\<60%)

- Priority badges: High (red), Medium (yellow), Low (green)

- Clickable Azure service links lead to official documentation

**Complete State Transition Summary**

STEP 0: Empty Dashboard

â†“ Click \"+ New Well-Architected Review\"

STEP 1: Create Assessment Form

â†“ Fill form â†’ Click \"Create Assessment\"

STEP 2: Dashboard with New Assessment

â†“ Click on assessment card

STEP 3: Upload Tab (Empty)

â†“ Click upload area

STEP 4: File Selection Dialog

â†“ Select files â†’ Click \"Open\"

STEP 5: Upload Tab with Documents

â†“ Auto-navigate after first upload

STEP 6: Artifact Findings Tab

â†“ Return to Upload tab â†’ Click \"Start Analysis\"

STEP 7: Progress Tab (Analyzing)

â†“ Real-time polling updates progress

â†“ Auto-navigate when progress === 100%

STEP 8: Results & Scorecard Tab

âœ“ Analysis Complete

**Key UX Patterns**

**Auto-Navigation Events:**

1.  **First file upload**Â â†’ Switches to Artifacts tab

2.  **Click Start Analysis**Â â†’ Switches to Progress tab

3.  **Analysis completes**Â â†’ Switches to Results tab

**Real-Time Updates:**

- **Polling interval:**Â 2 seconds

- **Monitored state:**Â status === \'analyzing\'

- **Updated elements:**

  - Progress percentage

  - Progress bar width

  - Pillar status indicators

  - Overall status badge

**Visual Feedback:**

- **Loading states:**Â Spinner icons, \"Uploading\...\" text

- **Status badges:**Â Color-coded (Yellow/Blue/Green/Red)

- **Progress animations:**Â Smooth transitions on progress bar

- **Completion indicators:**Â Checkmarks, success messages

**Data Flow:**

User Action â†’ Frontend API Call â†’ Backend Processing â†’ Database Update

â†“

Progress Callbacks

â†“

Frontend Polling â† Database Read â† Real-time Updates

â†“

UI Updates (Progress bar, pillar status, etc.)

This specification provides a complete walkthrough of every user interaction, screen state, technical implementation, and data flow through the entire Well-Architected Review process.
